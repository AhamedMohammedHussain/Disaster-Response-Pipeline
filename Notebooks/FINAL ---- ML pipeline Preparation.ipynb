{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!git clone https://github.com/AhamedMohammedHussain/Disaster-Response-Pipeline.git","execution_count":1,"outputs":[{"output_type":"stream","text":"Cloning into 'Disaster-Response-Pipeline'...\nremote: Enumerating objects: 39, done.\u001b[K\nremote: Counting objects: 100% (39/39), done.\u001b[K\nremote: Compressing objects: 100% (31/31), done.\u001b[K\nremote: Total 39 (delta 12), reused 19 (delta 3), pack-reused 0\u001b[K\nUnpacking objects: 100% (39/39), done.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cd Disaster-Response-Pipeline/","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/working/Disaster-Response-Pipeline\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python data/process_data.py data/disaster_messages.csv data/disaster_categories.csv data/DisasterResponse.db","execution_count":3,"outputs":[{"output_type":"stream","text":"Loading data...\n    MESSAGES: data/disaster_messages.csv\n    CATEGORIES: data/disaster_categories.csv\nCleaning data...\nSaving data...\n    DATABASE: data/DisasterResponse.db\n\tTable Name is DisasterResponse\nCleaned data saved to database!\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python models/train_classifier.py data/DisasterResponse.db models/classifier.pkl","execution_count":4,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package maxent_ne_chunker to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n[nltk_data] Downloading package words to /usr/share/nltk_data...\n[nltk_data]   Package words is already up-to-date!\nLoading data...\n    DATABASE: data/DisasterResponse.db\n['related', 'request', 'offer', 'aid_related', 'medical_help', 'medical_products', 'search_and_rescue', 'security', 'military', 'child_alone', 'water', 'food', 'shelter', 'clothing', 'money', 'missing_people', 'refugees', 'death', 'other_aid', 'infrastructure_related', 'transport', 'buildings', 'electricity', 'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure', 'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold', 'other_weather', 'direct_report']\nBuilding model...\nSaving model after building...\n    MODEL: models/save_after_model_build.pkl\nTraining model...\nFitting 5 folds for each of 54 candidates, totalling 270 fits\n[Parallel(n_jobs=-1)]: Using backend MultiprocessingBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.8min\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 39.6min\n[Parallel(n_jobs=-1)]: Done 270 out of 270 | elapsed: 67.3min finished\nSaving model after fitting...\n    MODEL: models/save_after_fit.pkl\nEvaluating model...\nrelated\n              precision    recall  f1-score   support\n\n           0       0.71      0.44      0.54      1244\n           1       0.84      0.94      0.89      3933\n           2       0.36      0.28      0.32        46\n\n    accuracy                           0.82      5223\n   macro avg       0.64      0.55      0.58      5223\nweighted avg       0.80      0.82      0.80      5223\n\nrequest\n              precision    recall  f1-score   support\n\n           0       0.91      0.98      0.94      4350\n           1       0.81      0.49      0.61       873\n\n    accuracy                           0.90      5223\n   macro avg       0.86      0.73      0.78      5223\nweighted avg       0.89      0.90      0.89      5223\n\noffer\n/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      5199\n           1       0.00      0.00      0.00        24\n\n    accuracy                           1.00      5223\n   macro avg       0.50      0.50      0.50      5223\nweighted avg       0.99      1.00      0.99      5223\n\naid_related\n              precision    recall  f1-score   support\n\n           0       0.79      0.85      0.82      3032\n           1       0.77      0.68      0.72      2191\n\n    accuracy                           0.78      5223\n   macro avg       0.78      0.77      0.77      5223\nweighted avg       0.78      0.78      0.78      5223\n\nmedical_help\n              precision    recall  f1-score   support\n\n           0       0.92      0.99      0.96      4809\n           1       0.49      0.06      0.11       414\n\n    accuracy                           0.92      5223\n   macro avg       0.71      0.53      0.53      5223\nweighted avg       0.89      0.92      0.89      5223\n\nmedical_products\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.97      4937\n           1       0.92      0.08      0.14       286\n\n    accuracy                           0.95      5223\n   macro avg       0.93      0.54      0.56      5223\nweighted avg       0.95      0.95      0.93      5223\n\nsearch_and_rescue\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.99      5071\n           1       0.83      0.07      0.12       152\n\n    accuracy                           0.97      5223\n   macro avg       0.90      0.53      0.55      5223\nweighted avg       0.97      0.97      0.96      5223\n\nsecurity\n              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99      5127\n           1       0.00      0.00      0.00        96\n\n    accuracy                           0.98      5223\n   macro avg       0.49      0.50      0.50      5223\nweighted avg       0.96      0.98      0.97      5223\n\nmilitary\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.98      5045\n           1       0.82      0.08      0.14       178\n\n    accuracy                           0.97      5223\n   macro avg       0.90      0.54      0.56      5223\nweighted avg       0.96      0.97      0.96      5223\n\nchild_alone\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      5223\n\n    accuracy                           1.00      5223\n   macro avg       1.00      1.00      1.00      5223\nweighted avg       1.00      1.00      1.00      5223\n\nwater\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.97      4876\n           1       0.85      0.32      0.47       347\n\n    accuracy                           0.95      5223\n   macro avg       0.90      0.66      0.72      5223\nweighted avg       0.95      0.95      0.94      5223\n\nfood\n              precision    recall  f1-score   support\n\n           0       0.95      0.99      0.97      4655\n           1       0.84      0.56      0.68       568\n\n    accuracy                           0.94      5223\n   macro avg       0.90      0.78      0.82      5223\nweighted avg       0.94      0.94      0.94      5223\n\nshelter\n              precision    recall  f1-score   support\n\n           0       0.94      0.99      0.97      4735\n           1       0.84      0.39      0.54       488\n\n    accuracy                           0.94      5223\n   macro avg       0.89      0.69      0.75      5223\nweighted avg       0.93      0.94      0.93      5223\n\nclothing\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99      5137\n           1       0.81      0.20      0.32        86\n\n    accuracy                           0.99      5223\n   macro avg       0.90      0.60      0.66      5223\nweighted avg       0.98      0.99      0.98      5223\n\nmoney\n              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99      5101\n           1       0.67      0.03      0.06       122\n\n    accuracy                           0.98      5223\n   macro avg       0.82      0.52      0.53      5223\nweighted avg       0.97      0.98      0.97      5223\n\nmissing_people\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99      5164\n           1       0.50      0.02      0.03        59\n\n    accuracy                           0.99      5223\n   macro avg       0.74      0.51      0.51      5223\nweighted avg       0.98      0.99      0.98      5223\n\nrefugees\n              precision    recall  f1-score   support\n\n           0       0.97      1.00      0.98      5053\n           1       0.64      0.04      0.08       170\n\n    accuracy                           0.97      5223\n   macro avg       0.80      0.52      0.53      5223\nweighted avg       0.96      0.97      0.95      5223\n\ndeath\n              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98      4977\n           1       0.85      0.14      0.24       246\n\n    accuracy                           0.96      5223\n   macro avg       0.90      0.57      0.61      5223\nweighted avg       0.95      0.96      0.94      5223\n\nother_aid\n              precision    recall  f1-score   support\n\n           0       0.87      1.00      0.93      4505\n           1       0.51      0.03      0.05       718\n\n    accuracy                           0.86      5223\n   macro avg       0.69      0.51      0.49      5223\nweighted avg       0.82      0.86      0.81      5223\n\ninfrastructure_related\n","name":"stdout"},{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.93      1.00      0.97      4880\n           1       0.00      0.00      0.00       343\n\n    accuracy                           0.93      5223\n   macro avg       0.47      0.50      0.48      5223\nweighted avg       0.87      0.93      0.90      5223\n\ntransport\n              precision    recall  f1-score   support\n\n           0       0.96      1.00      0.98      4979\n           1       0.70      0.09      0.15       244\n\n    accuracy                           0.96      5223\n   macro avg       0.83      0.54      0.57      5223\nweighted avg       0.95      0.96      0.94      5223\n\nbuildings\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.97      4920\n           1       0.85      0.13      0.22       303\n\n    accuracy                           0.95      5223\n   macro avg       0.90      0.56      0.60      5223\nweighted avg       0.94      0.95      0.93      5223\n\nelectricity\n              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99      5129\n           1       0.50      0.03      0.06        94\n\n    accuracy                           0.98      5223\n   macro avg       0.74      0.52      0.53      5223\nweighted avg       0.97      0.98      0.97      5223\n\ntools\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      1.00      5193\n           1       0.00      0.00      0.00        30\n\n    accuracy                           0.99      5223\n   macro avg       0.50      0.50      0.50      5223\nweighted avg       0.99      0.99      0.99      5223\n\nhospitals\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99      5159\n           1       0.00      0.00      0.00        64\n\n    accuracy                           0.99      5223\n   macro avg       0.49      0.50      0.50      5223\nweighted avg       0.98      0.99      0.98      5223\n\nshops\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00      5198\n           1       0.00      0.00      0.00        25\n\n    accuracy                           1.00      5223\n   macro avg       0.50      0.50      0.50      5223\nweighted avg       0.99      1.00      0.99      5223\n\naid_centers\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99      5165\n           1       0.00      0.00      0.00        58\n\n    accuracy                           0.99      5223\n   macro avg       0.49      0.50      0.50      5223\nweighted avg       0.98      0.99      0.98      5223\n\nother_infrastructure\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.98      4988\n           1       0.00      0.00      0.00       235\n\n    accuracy                           0.95      5223\n   macro avg       0.48      0.50      0.49      5223\nweighted avg       0.91      0.95      0.93      5223\n\nweather_related\n              precision    recall  f1-score   support\n\n           0       0.89      0.95      0.92      3760\n           1       0.84      0.70      0.76      1463\n\n    accuracy                           0.88      5223\n   macro avg       0.87      0.82      0.84      5223\nweighted avg       0.88      0.88      0.88      5223\n\nfloods\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.97      4790\n           1       0.93      0.46      0.62       433\n\n    accuracy                           0.95      5223\n   macro avg       0.94      0.73      0.80      5223\nweighted avg       0.95      0.95      0.94      5223\n\nstorm\n              precision    recall  f1-score   support\n\n           0       0.95      0.99      0.97      4721\n           1       0.80      0.49      0.61       502\n\n    accuracy                           0.94      5223\n   macro avg       0.87      0.74      0.79      5223\nweighted avg       0.93      0.94      0.93      5223\n\nfire\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      1.00      5176\n           1       0.50      0.04      0.08        47\n\n    accuracy                           0.99      5223\n   macro avg       0.75      0.52      0.54      5223\nweighted avg       0.99      0.99      0.99      5223\n\nearthquake\n              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.98      4733\n           1       0.88      0.81      0.84       490\n\n    accuracy                           0.97      5223\n   macro avg       0.93      0.90      0.91      5223\nweighted avg       0.97      0.97      0.97      5223\n\ncold\n              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99      5116\n           1       1.00      0.08      0.16       107\n\n    accuracy                           0.98      5223\n   macro avg       0.99      0.54      0.57      5223\nweighted avg       0.98      0.98      0.97      5223\n\nother_weather\n              precision    recall  f1-score   support\n\n           0       0.95      1.00      0.97      4949\n           1       0.52      0.04      0.08       274\n\n    accuracy                           0.95      5223\n   macro avg       0.74      0.52      0.53      5223\nweighted avg       0.93      0.95      0.93      5223\n\ndirect_report\n              precision    recall  f1-score   support\n\n           0       0.87      0.97      0.92      4260\n           1       0.76      0.38      0.50       963\n\n    accuracy                           0.86      5223\n   macro avg       0.82      0.67      0.71      5223\nweighted avg       0.85      0.86      0.84      5223\n\nSaving model after evaluating...\n    MODEL: models/classifier.pkl\nTrained model saved!\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}